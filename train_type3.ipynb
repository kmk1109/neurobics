{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROUTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercise = 'exer3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('dataset/exer3/raw/raw_paper_1670083733.npy'),\n",
       " WindowsPath('dataset/exer3/raw/raw_paper_1670083771.npy')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_set_group = sorted([x for x in Path(f\"./dataset/{exercise}/raw/\").glob(\"*.npy\")])\n",
    "tr_set_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if exercise == 'exer1':\n",
    "    actions = ['thumb','little']\n",
    "elif exercise == 'exer2':\n",
    "    actions = ['five', 'four', 'three', 'two', 'one']\n",
    "else:\n",
    "    actions = ['thumb','paper']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for fle in tr_set_group:\n",
    "    if len(data) == 0:\n",
    "        data = np.load(fle)\n",
    "    else:\n",
    "        data = np.concatenate([data, np.load(fle)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1102, 100)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1102, 99)\n",
      "(1102,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "x_data = data[:,:-1]\n",
    "labels = data[:,-1]\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1102, 2)\n"
     ]
    }
   ],
   "source": [
    "y_data = to_categorical(labels, num_classes=len(actions))\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(991, 99) (991, 2)\n",
      "(111, 99) (111, 2)\n"
     ]
    }
   ],
   "source": [
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "x_tr,x_val,y_tr,y_val = train_test_split(x_data, y_data, test_size=0.1, shuffle=True, random_state= 3)\n",
    "\n",
    "print(x_tr.shape, y_tr.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99,)\n",
      "(99,)\n"
     ]
    }
   ],
   "source": [
    "print(x_tr.shape[1:3])\n",
    "print(x_tr.shape[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                6400      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,042\n",
      "Trainable params: 9,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation = 'relu', input_shape = x_tr.shape[1:3]),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation = 'relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(16, activation ='relu'),\n",
    "    Dense(len(actions), activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['acc']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 0.0239 - acc: 0.9931 \n",
      "Epoch 1: val_acc improved from -inf to 1.00000, saving model to models/exer3\\classifier_acc_raw.h5\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.00000, saving model to models/exer3\\classifier_loss_raw.h5\n",
      "31/31 [==============================] - 2s 22ms/step - loss: 0.0208 - acc: 0.9939 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 1.0821e-04 - acc: 1.0000\n",
      "Epoch 2: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.2007e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 9.5169e-06 - acc: 1.0000\n",
      "Epoch 3: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.0188e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 8.5773e-05 - acc: 1.0000\n",
      "Epoch 4: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.1061e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 1.4716e-04 - acc: 1.0000\n",
      "Epoch 5: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.7163e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 6.4839e-05 - acc: 1.0000\n",
      "Epoch 6: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.3253e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.9356e-05 - acc: 1.0000\n",
      "Epoch 7: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.8846e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "22/31 [====================>.........] - ETA: 0s - loss: 5.6764e-05 - acc: 1.0000\n",
      "Epoch 8: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.2456e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 1.9097e-04 - acc: 1.0000\n",
      "Epoch 9: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.1561e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "21/31 [===================>..........] - ETA: 0s - loss: 6.1348e-06 - acc: 1.0000\n",
      "Epoch 10: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.2428e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "22/31 [====================>.........] - ETA: 0s - loss: 7.2823e-06 - acc: 1.0000\n",
      "Epoch 11: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.6841e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "20/31 [==================>...........] - ETA: 0s - loss: 4.7379e-06 - acc: 1.0000\n",
      "Epoch 12: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.5537e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "18/31 [================>.............] - ETA: 0s - loss: 2.0134e-05 - acc: 1.0000\n",
      "Epoch 13: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.2811e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "22/31 [====================>.........] - ETA: 0s - loss: 5.3473e-06 - acc: 1.0000\n",
      "Epoch 14: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.0199e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 2.8949e-05 - acc: 1.0000\n",
      "Epoch 15: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.8307e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 1.7829e-05 - acc: 1.0000\n",
      "Epoch 16: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.4565e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 6.0356e-05 - acc: 1.0000\n",
      "Epoch 17: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.2646e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 3.2616e-05 - acc: 1.0000\n",
      "Epoch 18: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.9496e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 2.6169e-05 - acc: 1.0000\n",
      "Epoch 19: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.1129e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 2.4289e-05 - acc: 1.0000\n",
      "Epoch 20: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.1699e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 4.1609e-06 - acc: 1.0000\n",
      "Epoch 21: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.0328e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 2.9986e-05 - acc: 1.0000\n",
      "Epoch 22: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.4427e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 9.5418e-07 - acc: 1.0000\n",
      "Epoch 23: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 8.3274e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 2.6300e-06 - acc: 1.0000\n",
      "Epoch 24: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.2105e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "22/31 [====================>.........] - ETA: 0s - loss: 1.4199e-06 - acc: 1.0000\n",
      "Epoch 25: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.0122e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 1.9807e-06 - acc: 1.0000\n",
      "Epoch 26: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.7452e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 6.3155e-05 - acc: 1.0000\n",
      "Epoch 27: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.9140e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 3.7253e-08 - acc: 1.0000\n",
      "Epoch 28: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3.0915e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 7.4261e-05 - acc: 1.0000\n",
      "Epoch 29: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7.4261e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 30: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.5296e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 4.3726e-07 - acc: 1.0000\n",
      "Epoch 31: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.2359e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.4753e-07 - acc: 1.0000\n",
      "Epoch 32: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 9.4753e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.0023e-06 - acc: 1.0000\n",
      "Epoch 33: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 9.0023e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 2.4165e-05 - acc: 1.0000\n",
      "Epoch 34: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.3409e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 4.2095e-08 - acc: 1.0000\n",
      "Epoch 35: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.0779e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 1.3642e-06 - acc: 1.0000\n",
      "Epoch 36: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.2337e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 2.9559e-07 - acc: 1.0000\n",
      "Epoch 37: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.6726e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 1.0351e-07 - acc: 1.0000\n",
      "Epoch 38: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.7514e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.4901e-09 - acc: 1.0000\n",
      "Epoch 39: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.4435e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 8.0234e-08 - acc: 1.0000\n",
      "Epoch 40: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 8.0234e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 6.5842e-05 - acc: 1.0000\n",
      "Epoch 41: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.0120e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 4.1386e-07 - acc: 1.0000\n",
      "Epoch 42: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3.8755e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.2167e-05 - acc: 1.0000\n",
      "Epoch 43: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.2167e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 44: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.3898e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 3.0827e-07 - acc: 1.0000\n",
      "Epoch 45: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3.0827e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.6700e-09 - acc: 1.0000\n",
      "Epoch 46: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.5638e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 1.6004e-07 - acc: 1.0000\n",
      "Epoch 47: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.2931e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 48: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 8.0595e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 3.3527e-08 - acc: 1.0000\n",
      "Epoch 49: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3.0313e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 1.3698e-06 - acc: 1.0000\n",
      "Epoch 50: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.0945e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "22/31 [====================>.........] - ETA: 0s - loss: 3.4653e-06 - acc: 1.0000\n",
      "Epoch 51: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.00000\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.4623e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 4.3462e-09 - acc: 1.0000\n",
      "Epoch 52: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.6914e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 53/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 1.7509e-07 - acc: 1.0000\n",
      "Epoch 53: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.1758e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 54/1000\n",
      "20/31 [==================>...........] - ETA: 0s - loss: 2.6838e-07 - acc: 1.0000\n",
      "Epoch 54: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.7417e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 55/1000\n",
      "21/31 [===================>..........] - ETA: 0s - loss: 9.4371e-08 - acc: 1.0000\n",
      "Epoch 55: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.1352e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 56/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 4.5133e-08 - acc: 1.0000\n",
      "Epoch 56: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.8838e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 57/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.4168e-07 - acc: 1.0000\n",
      "Epoch 57: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.3725e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 58/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 3.0601e-09 - acc: 1.0000\n",
      "Epoch 58: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.7667e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 59/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 2.4252e-07 - acc: 1.0000\n",
      "Epoch 59: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.6523e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 60/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 7.4173e-06 - acc: 1.0000\n",
      "Epoch 60: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.4668e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 61/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 3.6088e-10 - acc: 1.0000\n",
      "Epoch 61: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3.6088e-10 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 62/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.1459e-07 - acc: 1.0000\n",
      "Epoch 62: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.1459e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 63/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 2.9802e-09 - acc: 1.0000\n",
      "Epoch 63: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.8870e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 64/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 5.1511e-08 - acc: 1.0000\n",
      "Epoch 64: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.8237e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 65/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.8674e-07 - acc: 1.0000\n",
      "Epoch 65: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.8674e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 66/1000\n",
      "22/31 [====================>.........] - ETA: 0s - loss: 1.1159e-07 - acc: 1.0000\n",
      "Epoch 66: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 7.9270e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 67/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 1.8626e-08 - acc: 1.0000\n",
      "Epoch 67: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.7202e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 68/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 4.0978e-09 - acc: 1.0000\n",
      "Epoch 68: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3.9696e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 69/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 2.7944e-05 - acc: 1.0000\n",
      "Epoch 69: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.7070e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 70/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 5.7996e-07 - acc: 1.0000\n",
      "Epoch 70: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.4309e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 71/1000\n",
      "21/31 [===================>..........] - ETA: 0s - loss: 1.8272e-08 - acc: 1.0000\n",
      "Epoch 71: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 6.7963e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 72/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 3.8865e-07 - acc: 1.0000\n",
      "Epoch 72: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3.7332e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 73/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 2.1686e-08 - acc: 1.0000\n",
      "Epoch 73: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.5021e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 74/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 1.2280e-08 - acc: 1.0000\n",
      "Epoch 74: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.0826e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 75/1000\n",
      "21/31 [===================>..........] - ETA: 0s - loss: 8.2185e-06 - acc: 1.0000\n",
      "Epoch 75: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.5730e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 76/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.2013e-08 - acc: 1.0000\n",
      "Epoch 76: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.2013e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 77/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 8.8165e-09 - acc: 1.0000\n",
      "Epoch 77: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 9.0219e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 78/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 9.9341e-09 - acc: 1.0000\n",
      "Epoch 78: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 9.6233e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 79/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 3.7712e-07 - acc: 1.0000\n",
      "Epoch 79: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3.5315e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 80/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 80: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.8969e-04 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 81/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 6.1067e-08 - acc: 1.0000\n",
      "Epoch 81: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.7980e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 82/1000\n",
      "17/31 [===============>..............] - ETA: 0s - loss: 2.7392e-08 - acc: 1.0000\n",
      "Epoch 82: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.7050e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 83/1000\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 1.3767e-08 - acc: 1.0000\n",
      "Epoch 83: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.0345e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 84/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 84: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.2543e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 85/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.3634e-07 - acc: 1.0000\n",
      "Epoch 85: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.8260e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 86/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 7.1242e-06 - acc: 1.0000\n",
      "Epoch 86: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.9013e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 87/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.2048e-06 - acc: 1.0000\n",
      "Epoch 87: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.1295e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 88/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.5751e-08 - acc: 1.0000\n",
      "Epoch 88: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 9.5751e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 89/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 7.8602e-08 - acc: 1.0000\n",
      "Epoch 89: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 8.2278e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 90/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 90: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.2189e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 91/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 3.8426e-07 - acc: 1.0000\n",
      "Epoch 91: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 3.7224e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 92/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 8.2886e-08 - acc: 1.0000\n",
      "Epoch 92: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.4476e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 93/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 93: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.5350e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 94/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 5.2154e-09 - acc: 1.0000\n",
      "Epoch 94: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.0523e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 95/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 2.5435e-08 - acc: 1.0000\n",
      "Epoch 95: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.3818e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 96/1000\n",
      "22/31 [====================>.........] - ETA: 0s - loss: 2.7093e-08 - acc: 1.0000\n",
      "Epoch 96: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3.4403e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 97/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 3.1934e-07 - acc: 1.0000\n",
      "Epoch 97: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3.0935e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 98/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 3.9696e-09 - acc: 1.0000\n",
      "Epoch 98: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3.9696e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 99/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 99: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.3232e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 100/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 2.6215e-09 - acc: 1.0000\n",
      "Epoch 100: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.2855e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 101/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 3.0790e-07 - acc: 1.0000\n",
      "Epoch 101: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.00000\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 2.5000001187436284e-06.\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3.4462e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 5.0000e-05\n",
      "Epoch 102/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 102: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.5711e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 103/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 103: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.6825e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 104/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 5.8267e-07 - acc: 1.0000\n",
      "Epoch 104: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.2681e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 105/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.0611e-06 - acc: 1.0000\n",
      "Epoch 105: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.0279e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 106/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 7.9968e-08 - acc: 1.0000\n",
      "Epoch 106: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7.7467e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 107/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 2.4624e-07 - acc: 1.0000\n",
      "Epoch 107: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.7305e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 108/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 5.0291e-08 - acc: 1.0000\n",
      "Epoch 108: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 4.8718e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 109/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 4.3290e-08 - acc: 1.0000\n",
      "Epoch 109: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.0658e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 110/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 110: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.1789e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 111/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 1.2147e-07 - acc: 1.0000\n",
      "Epoch 111: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.0982e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 112/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 2.5345e-06 - acc: 1.0000\n",
      "Epoch 112: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.4552e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 113/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 2.8685e-08 - acc: 1.0000\n",
      "Epoch 113: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.7787e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 114/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 7.4506e-09 - acc: 1.0000\n",
      "Epoch 114: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 6.7363e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 115/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 115: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.2860e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 116/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.7650e-06 - acc: 1.0000\n",
      "Epoch 116: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.6533e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 117/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 5.4520e-07 - acc: 1.0000\n",
      "Epoch 117: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.2826e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 118/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.8524e-07 - acc: 1.0000\n",
      "Epoch 118: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.8524e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 119/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 1.0644e-09 - acc: 1.0000\n",
      "Epoch 119: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 9.6233e-10 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 120/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 3.0601e-09 - acc: 1.0000\n",
      "Epoch 120: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.3305e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 121/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 7.3175e-09 - acc: 1.0000\n",
      "Epoch 121: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.6160e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 122/1000\n",
      "20/31 [==================>...........] - ETA: 0s - loss: 4.4703e-09 - acc: 1.0000\n",
      "Epoch 122: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 1.0465e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 123/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 2.0448e-07 - acc: 1.0000\n",
      "Epoch 123: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.8500e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 124/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 2.6609e-09 - acc: 1.0000\n",
      "Epoch 124: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.4058e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 125/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 2.3724e-07 - acc: 1.0000\n",
      "Epoch 125: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.2216e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 126/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 2.2816e-07 - acc: 1.0000\n",
      "Epoch 126: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.0628e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 127/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 4.5966e-07 - acc: 1.0000\n",
      "Epoch 127: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.5966e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 128/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 1.0511e-08 - acc: 1.0000\n",
      "Epoch 128: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 9.5030e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 129/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.5398e-08 - acc: 1.0000\n",
      "Epoch 129: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.0437e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 130/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 6.2087e-08 - acc: 1.0000\n",
      "Epoch 130: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.4731e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 131/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 6.2172e-08 - acc: 1.0000\n",
      "Epoch 131: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.8220e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 132/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 4.4999e-06 - acc: 1.0000\n",
      "Epoch 132: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.4591e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 133/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 133: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 7.5784e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 134/1000\n",
      "21/31 [===================>..........] - ETA: 0s - loss: 3.4446e-07 - acc: 1.0000\n",
      "Epoch 134: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.4393e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 135/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 6.8693e-08 - acc: 1.0000\n",
      "Epoch 135: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.5454e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 136/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 1.1215e-06 - acc: 1.0000\n",
      "Epoch 136: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 9.0550e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 137/1000\n",
      "27/31 [=========================>....] - ETA: 0s - loss: 4.3875e-08 - acc: 1.0000\n",
      "Epoch 137: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.1506e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 138/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 2.9441e-06 - acc: 1.0000\n",
      "Epoch 138: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.8411e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 139/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 139: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.9006e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 140/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 4.5824e-07 - acc: 1.0000\n",
      "Epoch 140: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 4.2911e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 141/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 1.6631e-08 - acc: 1.0000\n",
      "Epoch 141: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.3216e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 142/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 3.0707e-07 - acc: 1.0000\n",
      "Epoch 142: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3.0707e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 143/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 143: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7.2823e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 144/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.6940e-06 - acc: 1.0000\n",
      "Epoch 144: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.6940e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 145/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 145: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.0418e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 146/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 146: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.5590e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 147/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.6233e-09 - acc: 1.0000\n",
      "Epoch 147: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 9.6233e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 148/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 4.0233e-08 - acc: 1.0000\n",
      "Epoch 148: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3.9094e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 149/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 149: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.4435e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 150/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 2.9160e-08 - acc: 1.0000\n",
      "Epoch 150: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.1003e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 151/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.3248e-06 - acc: 1.0000\n",
      "Epoch 151: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.00000\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 1.2500000821091816e-07.\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.2427e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 2.5000e-06\n",
      "Epoch 152/1000\n",
      "24/31 [======================>.......] - ETA: 0s - loss: 1.3815e-08 - acc: 1.0000\n",
      "Epoch 152: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.9005e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 153/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.3473e-08 - acc: 1.0000\n",
      "Epoch 153: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.3473e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 154/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 3.4868e-08 - acc: 1.0000\n",
      "Epoch 154: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.8389e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 155/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 5.1069e-07 - acc: 1.0000\n",
      "Epoch 155: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.7822e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 156/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 4.2062e-07 - acc: 1.0000\n",
      "Epoch 156: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.2062e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 157/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 157: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.1082e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 158/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 4.8316e-06 - acc: 1.0000\n",
      "Epoch 158: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.8316e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 159/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.9742e-07 - acc: 1.0000\n",
      "Epoch 159: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.9125e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 160/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 7.4506e-10 - acc: 1.0000\n",
      "Epoch 160: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.0265e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 161/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 3.0674e-08 - acc: 1.0000\n",
      "Epoch 161: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3.0674e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 162/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 6.9166e-08 - acc: 1.0000\n",
      "Epoch 162: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.9166e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 163/1000\n",
      "16/31 [==============>...............] - ETA: 0s - loss: 9.3132e-09 - acc: 1.0000\n",
      "Epoch 163: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 2.5380e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 164/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 164: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.1653e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 165/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 4.3804e-08 - acc: 1.0000\n",
      "Epoch 165: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.1019e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 166/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 5.4130e-08 - acc: 1.0000\n",
      "Epoch 166: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.4130e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 167/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.0248e-05 - acc: 1.0000\n",
      "Epoch 167: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.0248e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 168/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.2425e-06 - acc: 1.0000\n",
      "Epoch 168: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.2425e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 169/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 5.2137e-06 - acc: 1.0000\n",
      "Epoch 169: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 5.2137e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 170/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 9.1179e-08 - acc: 1.0000\n",
      "Epoch 170: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 9.1179e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 171/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 171: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.0146e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 172/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 3.3684e-07 - acc: 1.0000\n",
      "Epoch 172: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3.2631e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 173/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 8.2291e-05 - acc: 1.0000\n",
      "Epoch 173: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 8.2291e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 174/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 1.3115e-07 - acc: 1.0000\n",
      "Epoch 174: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.2438e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 175/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.3938e-08 - acc: 1.0000\n",
      "Epoch 175: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.3938e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 176/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.6246e-07 - acc: 1.0000\n",
      "Epoch 176: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.6246e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 177/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 3.4671e-06 - acc: 1.0000\n",
      "Epoch 177: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 177: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3.4671e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 178/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 7.4506e-09 - acc: 1.0000\n",
      "Epoch 178: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.5120e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 179/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 3.3464e-07 - acc: 1.0000\n",
      "Epoch 179: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 179: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 2.7207e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 180/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 1.3501e-06 - acc: 1.0000\n",
      "Epoch 180: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 180: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.3078e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 181/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 6.4502e-06 - acc: 1.0000\n",
      "Epoch 181: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 181: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.4502e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 182/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 4.0603e-06 - acc: 1.0000\n",
      "Epoch 182: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3.9333e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 183/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 3.5922e-09 - acc: 1.0000\n",
      "Epoch 183: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 183: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3.2479e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 184/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 184: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 184: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.4946e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 185/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.0352e-06 - acc: 1.0000\n",
      "Epoch 185: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 185: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.0352e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 186/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 2.1836e-07 - acc: 1.0000\n",
      "Epoch 186: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 186: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.0448e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 187/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 2.2724e-08 - acc: 1.0000\n",
      "Epoch 187: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 187: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.2254e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 188/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 7.2660e-07 - acc: 1.0000\n",
      "Epoch 188: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 188: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7.2660e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 189/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 2.0223e-08 - acc: 1.0000\n",
      "Epoch 189: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 189: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.8645e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 190/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 2.6957e-07 - acc: 1.0000\n",
      "Epoch 190: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.6114e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 191/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 9.3132e-10 - acc: 1.0000\n",
      "Epoch 191: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 191: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 8.4204e-10 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 192/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 192: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 192: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3.7531e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 193/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.1700e-07 - acc: 1.0000\n",
      "Epoch 193: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 193: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 2.1700e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 194/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 4.3676e-09 - acc: 1.0000\n",
      "Epoch 194: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 194: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 7.4581e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 195/1000\n",
      "30/31 [============================>.] - ETA: 0s - loss: 4.5944e-08 - acc: 1.0000\n",
      "Epoch 195: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 195: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.4507e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 196/1000\n",
      "28/31 [==========================>...] - ETA: 0s - loss: 7.0514e-09 - acc: 1.0000\n",
      "Epoch 196: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 196: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 6.3755e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 197/1000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 1.0000\n",
      "Epoch 197: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 197: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 8.1994e-07 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 198/1000\n",
      "31/31 [==============================] - ETA: 0s - loss: 3.4885e-09 - acc: 1.0000\n",
      "Epoch 198: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 198: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 3.4885e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 199/1000\n",
      "26/31 [========================>.....] - ETA: 0s - loss: 7.8804e-09 - acc: 1.0000\n",
      "Epoch 199: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 199: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.0658e-08 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 200/1000\n",
      "25/31 [=======================>......] - ETA: 0s - loss: 4.4703e-09 - acc: 1.0000\n",
      "Epoch 200: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.00000\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 6.9769e-09 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n",
      "Epoch 201/1000\n",
      "29/31 [===========================>..] - ETA: 0s - loss: 4.7573e-06 - acc: 1.0000\n",
      "Epoch 201: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 201: val_loss did not improve from 0.00000\n",
      "\n",
      "Epoch 201: ReduceLROnPlateau reducing learning rate to 6.250000694763003e-09.\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 4.4549e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000 - lr: 1.2500e-07\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_tr, y_tr,\n",
    "    validation_data = (x_val, y_val),\n",
    "    epochs = 1000,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(f'models/{exercise}/classifier_acc_raw.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "        ModelCheckpoint(f'models/{exercise}/classifier_loss_raw.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto'),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.05, patience=50, verbose=1, mode='auto'),\n",
    "        EarlyStopping(monitor='val_loss', min_delta=0, patience=200, mode='auto')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots(figsize=(16,10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'],'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'],'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'],'g',label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
